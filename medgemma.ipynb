{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c1aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import requests\n",
    "\n",
    "# API_BASE = \"https://fair2-dev.lutechdigitale.it/med-gemma\"\n",
    "\n",
    "# def predict_image(image_path: str, prompt: str = \"<start_of_image> findings:\", \n",
    "#                   poll_interval: float = 5.0, timeout: float = 600.0) -> str:\n",
    "#     \"\"\"\n",
    "#     1) POST /predict_image ‚Üí ottieni job_id\n",
    "#     2) Poll GET /jobs/{job_id} finch√© status != pending\n",
    "#     3) Ritorna il result o solleva se status == error\n",
    "#     \"\"\"\n",
    "#     # 1) Submit job\n",
    "#     with open(image_path, \"rb\") as f:\n",
    "#         files = {\"file\": (image_path, f, \"application/octet-stream\")}\n",
    "#         data = {\"prompt\": prompt}\n",
    "#         resp = requests.post(f\"{API_BASE}/predict_image\", files=files, data=data, timeout=(10, 30))\n",
    "#     resp.raise_for_status()\n",
    "#     if resp.status_code != 202:\n",
    "#         raise RuntimeError(f\"Unexpected status code {resp.status_code}: {resp.text}\")\n",
    "\n",
    "#     job_id = resp.json().get(\"job_id\")\n",
    "#     if not job_id:\n",
    "#         raise RuntimeError(f\"No job_id in response: {resp.text}\")\n",
    "\n",
    "#     # 2) Polling loop\n",
    "#     start = time.time()\n",
    "#     while True:\n",
    "#         # Evitiamo di eccedere il timeout complessivo\n",
    "#         elapsed = time.time() - start\n",
    "#         if elapsed > timeout:\n",
    "#             raise TimeoutError(f\"Job {job_id} did not complete within {timeout}s\")\n",
    "\n",
    "#         # Richiesta di stato\n",
    "#         r = requests.get(f\"{API_BASE}/jobs/{job_id}\", timeout=(5, 30))\n",
    "#         r.raise_for_status()\n",
    "#         job = r.json()\n",
    "\n",
    "#         status = job.get(\"status\")\n",
    "#         if status == \"pending\":\n",
    "#             # ancora in corso: attendi e riprova\n",
    "#             time.sleep(poll_interval)\n",
    "#             continue\n",
    "#         elif status == \"done\":\n",
    "#             # tutto ok: restituisci result\n",
    "#             result = job.get(\"result\")\n",
    "#             if result is None:\n",
    "#                 raise RuntimeError(f\"Job {job_id} completed without result\")\n",
    "#             return result\n",
    "#         elif status == \"error\":\n",
    "#             # job fallito: dettaglio\n",
    "#             detail = job.get(\"detail\", \"No detail provided\")\n",
    "#             raise RuntimeError(f\"Job {job_id} error: {detail}\")\n",
    "#         else:\n",
    "#             # stato inatteso\n",
    "#             raise RuntimeError(f\"Unknown job status '{status}' for job {job_id}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2032d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modulo models importato correttamente\n",
      "üîß Inizializzando i modelli...\n",
      "‚ùå Errore durante l'inizializzazione dei modelli: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/models/medgemma'. Use `repo_type` argument if needed.\n",
      "Traceback completo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\medgemma_env\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 470, in cached_files\n",
      "    hf_hub_download(\n",
      "    ~~~~~~~~~~~~~~~^\n",
      "        path_or_repo_id,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    ...<10 lines>...\n",
      "        local_files_only=local_files_only,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\medgemma_env\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 106, in _inner_fn\n",
      "    validate_repo_id(arg_value)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\medgemma_env\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 154, in validate_repo_id\n",
      "    raise HFValidationError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/models/medgemma'. Use `repo_type` argument if needed.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nicolo.petruzzella\\AppData\\Local\\Temp\\ipykernel_20332\\2202547964.py\", line 30, in <module>\n",
      "    init_models()\n",
      "    ~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\models.py\", line 24, in init_models\n",
      "    text_pipe = pipeline(\n",
      "        \"text-generation\",\n",
      "    ...<2 lines>...\n",
      "        low_cpu_mem_usage=True,\n",
      "    )\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\medgemma_env\\Lib\\site-packages\\transformers\\pipelines\\__init__.py\", line 892, in pipeline\n",
      "    resolved_config_file = cached_file(\n",
      "        pretrained_model_name_or_path,\n",
      "    ...<5 lines>...\n",
      "        **hub_kwargs,\n",
      "    )\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\medgemma_env\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 312, in cached_file\n",
      "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\medgemma_env\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 523, in cached_files\n",
      "    _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) for filename in full_filenames\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\medgemma_env\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 140, in _get_cache_file_to_return\n",
      "    resolved_file = try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir=cache_dir, revision=revision)\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\medgemma_env\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 106, in _inner_fn\n",
      "    validate_repo_id(arg_value)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "  File \"c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\medgemma_env\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 154, in validate_repo_id\n",
      "    raise HFValidationError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/models/medgemma'. Use `repo_type` argument if needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Controllo struttura cartelle:\n",
      "   X/: ‚úÖ 1 immagini trovate\n",
      "      - newplot (1).png (32971 bytes)\n",
      "   Y/: ‚úÖ 1 immagini trovate\n",
      "      - newplot (2).png (33700 bytes)\n",
      "   Z/: ‚úÖ 1 immagini trovate\n",
      "      - newplot (3).png (55817 bytes)\n",
      "üîß TESTING MODEL INITIALIZATION\n",
      "========================================\n",
      "‚ùå Modelli non inizializzati! Chiama init_models() prima del test.\n",
      "\n",
      "‚ùå ATTENZIONE: Il modello non √® inizializzato correttamente!\n",
      "   Controlla il file models.py e assicurati che:\n",
      "   1. Il modello sia caricato correttamente\n",
      "   2. Le dipendenze siano installate\n",
      "   3. I path dei modelli siano corretti\n",
      "   4. Le variabili d'ambiente siano configurate\n",
      "\n",
      "‚ùå Salto i test perch√© il modello non funziona\n",
      "\n",
      "üíæ Risultati salvati in: test_results_20250703_184201.json\n",
      "\n",
      "üîç INFORMAZIONI PER TROUBLESHOOTING:\n",
      "==================================================\n",
      "üìÅ Directory di lavoro: c:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\n",
      "üìÅ Directory base immagini: C:\\Users\\nicolo.petruzzella\\OneDrive - LUTECH SPA\\Desktop\\promptMRI\\imagesPrompt\n",
      "üêç Python path: ['C:\\\\Users\\\\nicolo.petruzzella\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\python313.zip', 'C:\\\\Users\\\\nicolo.petruzzella\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\DLLs', 'C:\\\\Users\\\\nicolo.petruzzella\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib', 'C:\\\\Users\\\\nicolo.petruzzella\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313', 'c:\\\\Users\\\\nicolo.petruzzella\\\\OneDrive - LUTECH SPA\\\\Desktop\\\\promptMRI\\\\medgemma_env', '', 'c:\\\\Users\\\\nicolo.petruzzella\\\\OneDrive - LUTECH SPA\\\\Desktop\\\\promptMRI\\\\medgemma_env\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\nicolo.petruzzella\\\\OneDrive - LUTECH SPA\\\\Desktop\\\\promptMRI\\\\medgemma_env\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\nicolo.petruzzella\\\\OneDrive - LUTECH SPA\\\\Desktop\\\\promptMRI\\\\medgemma_env\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\nicolo.petruzzella\\\\OneDrive - LUTECH SPA\\\\Desktop\\\\promptMRI\\\\medgemma_env\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\nicolo.petruzzella\\\\OneDrive - LUTECH SPA\\\\Desktop\\\\promptMRI', 'C:\\\\Users\\\\nicolo.petruzzella\\\\OneDrive - LUTECH SPA\\\\Desktop\\\\promptMRI', 'C:\\\\Users\\\\nicolo.petruzzella\\\\OneDrive - LUTECH SPA\\\\Desktop\\\\promptMRI', 'C:\\\\Users\\\\nicolo.petruzzella\\\\OneDrive - LUTECH SPA\\\\Desktop\\\\promptMRI']\n",
      "üì¶ Moduli importati: ['charset_normalizer.models', 'requests.packages.charset_normalizer.models', 'requests.packages.chardet.models', 'requests.models', 'tokenizers.models', 'transformers.models', 'transformers.models.auto', 'transformers.models.auto.configuration_auto', 'transformers.models.auto.auto_factory', 'transformers.models.auto.feature_extraction_auto', 'transformers.models.auto.image_processing_auto', 'transformers.models.auto.modeling_auto', 'transformers.models.encoder_decoder', 'transformers.models.encoder_decoder.configuration_encoder_decoder', 'transformers.models.auto.tokenization_auto', 'transformers.models.auto.processing_auto', 'transformers.models.bert', 'transformers.models.bert.tokenization_bert', 'transformers.models.bert.tokenization_bert_fast', 'transformers.models.speecht5', 'transformers.models.speecht5.configuration_speecht5', 'transformers.models.speecht5.modeling_speecht5', 'httpx._models', 'langchain_core.language_models', 'langchain_core.language_models.base', 'langchain_core.language_models._utils', 'langchain_core.language_models.chat_models', 'langchain_core.language_models.llms', 'langchain_huggingface.chat_models.huggingface', 'langchain_huggingface.chat_models', 'models']\n",
      "\n",
      "üîç CONTROLLI AGGIUNTIVI:\n",
      "==============================\n",
      "‚úÖ File models.py trovato (3764 bytes)\n",
      "üì∑ Totale immagini trovate: 3\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Test Prompt Engineering per Analisi Brain Scan - Alzheimer\n",
    "# \n",
    "# Questo notebook testa diversi prompt ottimizzati per l'analisi di immagini cerebrali\n",
    "# con overlay Grad-CAM usando il modello MedGemma.\n",
    "\n",
    "# %% [markdown]\n",
    "## Setup e Import\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "# Assicuriamoci che la cartella del notebook sia nel path di import\n",
    "sys.path.append(str(Path().resolve()))\n",
    "\n",
    "# Import delle funzioni dal modulo models\n",
    "try:\n",
    "    from models import predict_image, init_models\n",
    "    print(\"‚úÖ Modulo models importato correttamente\")\n",
    "    \n",
    "    # IMPORTANTE: Inizializza i modelli prima di usarli\n",
    "    print(\"üîß Inizializzando i modelli...\")\n",
    "    try:\n",
    "        init_models()\n",
    "        print(\"‚úÖ Modelli inizializzati correttamente!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore durante l'inizializzazione dei modelli: {e}\")\n",
    "        print(\"Traceback completo:\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Errore nell'importazione del modulo models: {e}\")\n",
    "    print(\"Assicurati che il file models.py sia nella stessa directory del notebook\")\n",
    "    print(\"Traceback completo:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "# %% [markdown]\n",
    "## Configurazione Paths e Controlli\n",
    "\n",
    "# %%\n",
    "# Cartella immagini organizzata per asse X/Y/Z\n",
    "BASE_DIR = Path(\"imagesPrompt\")\n",
    "\n",
    "# Verifica esistenza cartelle\n",
    "print(\"üìÅ Controllo struttura cartelle:\")\n",
    "for axis in [\"X\", \"Y\", \"Z\"]:\n",
    "    axis_dir = BASE_DIR / axis\n",
    "    if axis_dir.is_dir():\n",
    "        img_count = len(list(axis_dir.glob(\"*.png\"))) + len(list(axis_dir.glob(\"*.jpg\"))) + len(list(axis_dir.glob(\"*.jpeg\")))\n",
    "        print(f\"   {axis}/: ‚úÖ {img_count} immagini trovate\")\n",
    "        \n",
    "        # Elenca i file per debug\n",
    "        image_files = list(axis_dir.glob(\"*.png\")) + list(axis_dir.glob(\"*.jpg\")) + list(axis_dir.glob(\"*.jpeg\"))\n",
    "        for img in image_files:\n",
    "            print(f\"      - {img.name} ({img.stat().st_size} bytes)\")\n",
    "    else:\n",
    "        print(f\"   {axis}/: ‚ùå Directory non trovata\")\n",
    "\n",
    "# %% [markdown]\n",
    "## Definizione Prompt Ottimizzati\n",
    "\n",
    "# %%\n",
    "# Prompt base migliorato\n",
    "base_prompt = \"\"\"\n",
    "TASK: Analyze this Grad-CAM brain visualization for Alzheimer's disease indicators.\n",
    "\n",
    "CONTEXT:\n",
    "- This image shows a Grad-CAM heatmap overlaid on a brain scan\n",
    "- Red/yellow areas indicate high neural network activation (high confidence regions)\n",
    "- Green/blue areas indicate lower activation\n",
    "- Focus on medically relevant brain regions for Alzheimer's pathology\n",
    "\n",
    "ANALYSIS FRAMEWORK:\n",
    "1. **Highlighted Regions**: Identify specific brain areas with high Grad-CAM activation\n",
    "2. **Medical Relevance**: Assess if highlighted regions align with known Alzheimer's patterns:\n",
    "   - Hippocampus (memory formation)\n",
    "   - Entorhinal cortex (memory gateway)\n",
    "   - Temporal cortex (semantic memory)\n",
    "   - Parietal cortex (spatial processing)\n",
    "3. **Activation Pattern**: Evaluate the distribution and intensity of highlights\n",
    "4. **Clinical Assessment**: Provide diagnostic confidence and reasoning\n",
    "\n",
    "REQUIRED OUTPUT FORMAT:\n",
    "- **Primary Findings**: [Specific observations about highlighted regions]\n",
    "- **Alzheimer's Indicators**: [Present/Absent with medical justification]\n",
    "- **Confidence Level**: [High/Medium/Low with reasoning]\n",
    "- **Recommended Actions**: [Clinical next steps or additional tests needed]\n",
    "\n",
    "IMPORTANT: Base analysis on established Alzheimer's neuroanatomy and the specific Grad-CAM activation patterns visible in this image.\n",
    "\"\"\"\n",
    "\n",
    "# Prompt specifici per ogni asse\n",
    "axis_prompts = {\n",
    "    \"X\": \"\"\"\n",
    "SPECIALIZED ANALYSIS: Sagittal Brain Slice for Alzheimer's Detection\n",
    "\n",
    "FOCUS AREAS for this lateral brain view:\n",
    "- Medial temporal lobe structures\n",
    "- Posterior cingulate cortex\n",
    "- Precuneus region\n",
    "- Corpus callosum integrity\n",
    "\n",
    "GRAD-CAM INTERPRETATION:\n",
    "- Examine medial temporal activation patterns\n",
    "- Assess posterior brain region highlights\n",
    "- Evaluate activation consistency with Alzheimer's progression\n",
    "\n",
    "OUTPUT: Provide sagittal-specific anatomical assessment.\n",
    "\"\"\",\n",
    "    \"Y\": \"\"\"\n",
    "SPECIALIZED ANALYSIS: Coronal Brain Slice for Alzheimer's Detection\n",
    "\n",
    "FOCUS AREAS for this frontal brain view:\n",
    "- Hippocampal head and body visualization\n",
    "- Amygdala region\n",
    "- Temporal horn enlargement\n",
    "- Cortical thickness assessment\n",
    "\n",
    "GRAD-CAM INTERPRETATION:\n",
    "- Focus on bilateral hippocampal activation\n",
    "- Assess temporal lobe symmetry in highlights\n",
    "- Evaluate activation intensity relative to normal patterns\n",
    "\n",
    "OUTPUT: Provide coronal-specific structural findings.\n",
    "\"\"\",\n",
    "    \"Z\": \"\"\"\n",
    "SPECIALIZED ANALYSIS: Axial Brain Slice for Alzheimer's Detection\n",
    "\n",
    "FOCUS AREAS for this horizontal brain slice:\n",
    "- Hippocampal formations (bilateral)\n",
    "- Ventricular enlargement (compensatory to atrophy)\n",
    "- Cortical thickness in temporal regions\n",
    "- White matter integrity\n",
    "\n",
    "GRAD-CAM INTERPRETATION:\n",
    "- Assess if red/yellow highlights align with hippocampal regions\n",
    "- Evaluate symmetry of activation patterns\n",
    "- Note any unusual activation in non-typical regions\n",
    "\n",
    "OUTPUT: Provide axial-specific findings with anatomical precision.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# Prompt alternativi per confronto\n",
    "alternative_prompts = {\n",
    "    \"concise\": \"\"\"\n",
    "Analyze this Grad-CAM brain scan for Alzheimer's indicators.\n",
    "\n",
    "Key points:\n",
    "- Red/yellow = high AI confidence areas\n",
    "- Focus on hippocampus, temporal cortex, parietal regions\n",
    "- Assess if activation patterns match known Alzheimer's pathology\n",
    "\n",
    "Provide:\n",
    "1. Main findings\n",
    "2. Alzheimer's likelihood (High/Medium/Low)\n",
    "3. Key anatomical observations\n",
    "4. Clinical recommendation\n",
    "\n",
    "Be specific and medical-accurate.\n",
    "\"\"\",\n",
    "    \n",
    "    \"detailed\": \"\"\"\n",
    "COMPREHENSIVE GRAD-CAM BRAIN ANALYSIS FOR ALZHEIMER'S DISEASE\n",
    "\n",
    "INSTRUCTIONS:\n",
    "You are analyzing a Grad-CAM visualization overlaid on a brain scan. This technique highlights regions where a deep learning model shows highest confidence in its Alzheimer's vs. normal brain classification.\n",
    "\n",
    "INTERPRETATION KEY:\n",
    "- Red/Hot colors: Maximum model activation (highest confidence regions)\n",
    "- Yellow/Orange: High activation\n",
    "- Green: Moderate activation  \n",
    "- Blue/Cold colors: Low activation\n",
    "- Consider both the presence AND absence of activation in key regions\n",
    "\n",
    "SYSTEMATIC ANALYSIS REQUIRED:\n",
    "\n",
    "1. ANATOMICAL REGION IDENTIFICATION:\n",
    "   - Identify all brain regions showing significant activation\n",
    "   - Note the intensity and distribution of highlights\n",
    "   - Compare bilateral symmetry\n",
    "\n",
    "2. ALZHEIMER'S PATHOLOGY CORRELATION:\n",
    "   - Hippocampus: Early and severe atrophy in AD\n",
    "   - Entorhinal cortex: First area affected in AD\n",
    "   - Temporal cortex: Language and semantic memory\n",
    "   - Parietal cortex: Spatial processing and attention\n",
    "   - Posterior cingulate: Default mode network disruption\n",
    "\n",
    "3. CLINICAL INTERPRETATION:\n",
    "   - Does the activation pattern support AD diagnosis?\n",
    "   - Are there unexpected activations that might indicate other conditions?\n",
    "   - What is the confidence level of this analysis?\n",
    "\n",
    "4. DIFFERENTIAL CONSIDERATIONS:\n",
    "   - Could this represent normal aging?\n",
    "   - Other neurodegenerative conditions?\n",
    "   - Technical artifacts in the scan?\n",
    "\n",
    "REQUIRED OUTPUT:\n",
    "Provide a structured medical report with clear diagnostic reasoning.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "## Funzione di Test Migliorata\n",
    "\n",
    "# %%\n",
    "def test_prompt_on_images(prompt_type=\"base\", limit_per_axis=3, verbose=True, debug=False):\n",
    "    \"\"\"\n",
    "    Testa i prompt sulle immagini organizzate per asse\n",
    "    \n",
    "    Args:\n",
    "        prompt_type: \"base\", \"axis_specific\", \"concise\", \"detailed\"\n",
    "        limit_per_axis: numero massimo di immagini per asse da testare\n",
    "        verbose: se stampare output dettagliato\n",
    "        debug: se abilitare debug extra\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Estensioni immagini supportate\n",
    "    image_extensions = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\"}\n",
    "    \n",
    "    # Loop attraverso assi X, Y, Z\n",
    "    for axis in [\"X\", \"Y\", \"Z\"]:\n",
    "        axis_dir = BASE_DIR / axis\n",
    "        \n",
    "        if not axis_dir.is_dir():\n",
    "            print(f\"‚ö†Ô∏è  Directory non trovata: {axis_dir}\")\n",
    "            continue\n",
    "        \n",
    "        # Trova tutte le immagini nell'asse\n",
    "        image_files = []\n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(axis_dir.glob(f\"*{ext}\"))\n",
    "        \n",
    "        # Ordina e limita il numero di immagini\n",
    "        image_files = sorted(image_files)[:limit_per_axis]\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"‚ö†Ô∏è  Nessuna immagine trovata in {axis_dir}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüîç Testando asse {axis} ({len(image_files)} immagini):\")\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                # Verifica che il file esista e sia leggibile\n",
    "                if not img_path.exists():\n",
    "                    raise FileNotFoundError(f\"File non trovato: {img_path}\")\n",
    "                \n",
    "                if img_path.stat().st_size == 0:\n",
    "                    raise ValueError(f\"File vuoto: {img_path}\")\n",
    "                \n",
    "                # Seleziona il prompt appropriato\n",
    "                if prompt_type == \"axis_specific\":\n",
    "                    selected_prompt = f\"{base_prompt}\\n\\n{axis_prompts[axis]}\"\n",
    "                elif prompt_type in alternative_prompts:\n",
    "                    selected_prompt = alternative_prompts[prompt_type]\n",
    "                else:\n",
    "                    selected_prompt = base_prompt\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"   üì∑ Analizzando {img_path.name}...\", end=\" \")\n",
    "                \n",
    "                if debug:\n",
    "                    print(f\"\\n   üìù Prompt utilizzato: {selected_prompt[:100]}...\")\n",
    "                    print(f\"   üìÅ Path completo: {img_path}\")\n",
    "                \n",
    "                # Leggi l'immagine come bytes\n",
    "                with open(img_path, 'rb') as f:\n",
    "                    image_bytes = f.read()\n",
    "                \n",
    "                # Chiamata alla funzione predict_image (che si aspetta bytes, non path)\n",
    "                result = predict_image(image_bytes, selected_prompt)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(\"‚úÖ\")\n",
    "                    if debug:\n",
    "                        print(f\"      Risultato completo: {result}\")\n",
    "                    else:\n",
    "                        print(f\"      Risultato: {result[:100]}{'...' if len(result) > 100 else ''}\")\n",
    "                \n",
    "                results.append({\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"axis\": axis,\n",
    "                    \"filename\": img_path.name,\n",
    "                    \"prompt_type\": prompt_type,\n",
    "                    \"result\": result,\n",
    "                    \"status\": \"success\",\n",
    "                    \"result_length\": len(result)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"ERROR: {str(e)}\"\n",
    "                if verbose:\n",
    "                    print(f\"‚ùå {error_msg}\")\n",
    "                \n",
    "                if debug:\n",
    "                    print(f\"   üîç Traceback completo:\")\n",
    "                    traceback.print_exc()\n",
    "                \n",
    "                results.append({\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"axis\": axis,\n",
    "                    \"filename\": img_path.name,\n",
    "                    \"prompt_type\": prompt_type,\n",
    "                    \"result\": error_msg,\n",
    "                    \"status\": \"error\",\n",
    "                    \"result_length\": 0\n",
    "                })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# %% [markdown]\n",
    "## Funzione per Testare Inizializzazione Modello\n",
    "\n",
    "# %%\n",
    "def test_model_initialization():\n",
    "    \"\"\"\n",
    "    Testa se il modello √® correttamente inizializzato\n",
    "    \"\"\"\n",
    "    print(\"üîß TESTING MODEL INITIALIZATION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Verifica che i modelli siano stati inizializzati\n",
    "        from models import image_model, processor\n",
    "        \n",
    "        if image_model is None or processor is None:\n",
    "            print(\"‚ùå Modelli non inizializzati! Chiama init_models() prima del test.\")\n",
    "            return False\n",
    "            \n",
    "        print(\"‚úÖ Variabili globali del modello sembrano OK\")\n",
    "        \n",
    "        # Trova la prima immagine disponibile per test\n",
    "        test_img = None\n",
    "        for axis in [\"X\", \"Y\", \"Z\"]:\n",
    "            axis_dir = BASE_DIR / axis\n",
    "            if axis_dir.is_dir():\n",
    "                imgs = list(axis_dir.glob(\"*.png\")) + list(axis_dir.glob(\"*.jpg\"))\n",
    "                if imgs:\n",
    "                    test_img = imgs[0]\n",
    "                    break\n",
    "        \n",
    "        if test_img:\n",
    "            print(f\"üéØ Testando con immagine: {test_img.name}\")\n",
    "            \n",
    "            # Leggi l'immagine come bytes\n",
    "            with open(test_img, 'rb') as f:\n",
    "                image_bytes = f.read()\n",
    "            \n",
    "            # Test con prompt semplice\n",
    "            simple_prompt = \"Describe what you see in this image.\"\n",
    "            result = predict_image(image_bytes, simple_prompt)\n",
    "            \n",
    "            print(\"‚úÖ Modello funziona correttamente!\")\n",
    "            print(f\"   Risultato di test: {result[:100]}{'...' if len(result) > 100 else ''}\")\n",
    "            return True\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Nessuna immagine trovata per il test\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore durante il test: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# %% [markdown]\n",
    "## Esecuzione Test Preliminari\n",
    "\n",
    "# %%\n",
    "# Prima testa l'inizializzazione del modello\n",
    "model_works = test_model_initialization()\n",
    "\n",
    "if not model_works:\n",
    "    print(\"\\n‚ùå ATTENZIONE: Il modello non √® inizializzato correttamente!\")\n",
    "    print(\"   Controlla il file models.py e assicurati che:\")\n",
    "    print(\"   1. Il modello sia caricato correttamente\")\n",
    "    print(\"   2. Le dipendenze siano installate\")\n",
    "    print(\"   3. I path dei modelli siano corretti\")\n",
    "    print(\"   4. Le variabili d'ambiente siano configurate\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Modello OK, procedo con i test dei prompt\")\n",
    "\n",
    "# %% [markdown]\n",
    "## Esecuzione Test Prompt (solo se il modello funziona)\n",
    "\n",
    "# %%\n",
    "if model_works:\n",
    "    # Test con prompt base\n",
    "    print(\"\\nüöÄ INIZIO TEST CON PROMPT BASE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    base_results = test_prompt_on_images(\n",
    "        prompt_type=\"base\", \n",
    "        limit_per_axis=1,  # Inizia con 1 immagine per asse\n",
    "        verbose=True,\n",
    "        debug=True  # Abilita debug per il primo test\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Test completato: {len(base_results)} immagini processate\")\n",
    "    \n",
    "    # Se il test base funziona, continua con gli altri\n",
    "    if any(r['status'] == 'success' for r in base_results):\n",
    "        print(\"\\n‚úÖ Test base riuscito! Procedo con test aggiuntivi...\")\n",
    "        \n",
    "        # Test con prompt specifici per asse\n",
    "        print(\"\\nüöÄ TEST CON PROMPT SPECIFICI PER ASSE\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        axis_results = test_prompt_on_images(\n",
    "            prompt_type=\"axis_specific\", \n",
    "            limit_per_axis=1,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Test con prompt alternativi\n",
    "        print(\"\\nüöÄ TEST CON PROMPT CONCISO\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        concise_results = test_prompt_on_images(\n",
    "            prompt_type=\"concise\", \n",
    "            limit_per_axis=1,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ùå Test base fallito, controllo necessario prima di continuare\")\n",
    "        axis_results = []\n",
    "        concise_results = []\n",
    "        \n",
    "else:\n",
    "    print(\"\\n‚ùå Salto i test perch√© il modello non funziona\")\n",
    "    base_results = []\n",
    "    axis_results = []\n",
    "    concise_results = []\n",
    "\n",
    "# %% [markdown]\n",
    "## Analisi e Salvataggio Risultati\n",
    "\n",
    "# %%\n",
    "# Combina tutti i risultati\n",
    "all_results = {\n",
    "    \"base_prompt_results\": base_results,\n",
    "    \"axis_specific_results\": axis_results,\n",
    "    \"concise_results\": concise_results,\n",
    "    \"test_timestamp\": datetime.now().isoformat(),\n",
    "    \"model_initialization_test\": model_works,\n",
    "    \"test_config\": {\n",
    "        \"limit_per_axis\": 1,\n",
    "        \"base_dir\": str(BASE_DIR),\n",
    "        \"prompt_types_tested\": [\"base\", \"axis_specific\", \"concise\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salva in file JSON\n",
    "results_file = f\"test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(results_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Risultati salvati in: {results_file}\")\n",
    "\n",
    "# Mostra statistiche finali\n",
    "if base_results:\n",
    "    df_base = pd.DataFrame(base_results)\n",
    "    print(f\"\\nüìä STATISTICHE FINALI:\")\n",
    "    print(f\"   - Immagini processate: {len(df_base)}\")\n",
    "    print(f\"   - Successi: {len(df_base[df_base['status'] == 'success'])}\")\n",
    "    print(f\"   - Errori: {len(df_base[df_base['status'] == 'error'])}\")\n",
    "    \n",
    "    if any(df_base['status'] == 'success'):\n",
    "        print(f\"   - Lunghezza media risposte: {df_base[df_base['status'] == 'success']['result_length'].mean():.0f} caratteri\")\n",
    "\n",
    "# %% [markdown]\n",
    "## Troubleshooting e Debug\n",
    "\n",
    "# %%\n",
    "print(\"\\nüîç INFORMAZIONI PER TROUBLESHOOTING:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìÅ Directory di lavoro: {Path.cwd()}\")\n",
    "print(f\"üìÅ Directory base immagini: {BASE_DIR.resolve()}\")\n",
    "print(f\"üêç Python path: {sys.path}\")\n",
    "print(f\"üì¶ Moduli importati: {[m for m in sys.modules.keys() if 'models' in m]}\")\n",
    "\n",
    "# Controlli aggiuntivi per debugging\n",
    "print(\"\\nüîç CONTROLLI AGGIUNTIVI:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Controlla se il file models.py esiste\n",
    "models_file = Path(\"models.py\")\n",
    "if models_file.exists():\n",
    "    print(f\"‚úÖ File models.py trovato ({models_file.stat().st_size} bytes)\")\n",
    "else:\n",
    "    print(\"‚ùå File models.py NON trovato\")\n",
    "\n",
    "# Controlla le immagini\n",
    "total_images = 0\n",
    "for axis in [\"X\", \"Y\", \"Z\"]:\n",
    "    axis_dir = BASE_DIR / axis\n",
    "    if axis_dir.is_dir():\n",
    "        imgs = list(axis_dir.glob(\"*.png\")) + list(axis_dir.glob(\"*.jpg\")) + list(axis_dir.glob(\"*.jpeg\"))\n",
    "        total_images += len(imgs)\n",
    "\n",
    "print(f\"üì∑ Totale immagini trovate: {total_images}\")\n",
    "\n",
    "if total_images == 0:\n",
    "    print(\"‚ö†Ô∏è ATTENZIONE: Nessuna immagine trovata!\")\n",
    "    print(\"   Assicurati che le immagini siano nelle cartelle corrette:\")\n",
    "    print(\"   - imagesPrompt/X/\")\n",
    "    print(\"   - imagesPrompt/Y/\")\n",
    "    print(\"   - imagesPrompt/Z/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45e0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference result: You are a medical AI assistant. Analyze this brain scan and explain what the Grad-CAM highlights.\n",
      "This image is provided for inference of neural networl classification for alzheimer's disease. Tell me if there is any sign of alzheimer's disease in this image.\n",
      "Findings:\n",
      "The Grad-CAM visualization highlights the regions of the brain that are most important for the model's decision-making process. In this case, the visualization shows that the model is focusing on areas such as the hippocampus, amygdala, and cortex. These regions are known to be involved in memory, emotion, and cognitive function, which are all affected in Alzheimer's disease.\n",
      "\n",
      "Based on the Grad-CAM visualization, it is difficult to definitively diagnose Alzheimer's disease from this single image. However, the model is highlighting areas that are typically affected in Alzheimer's disease, which suggests that the image may contain features that are indicative of the disease. Further analysis of the image, along with other clinical information, would be needed to make a\n"
     ]
    }
   ],
   "source": [
    "#img_file = \"grad_cam_images_gradcam_visualization116.png\"\n",
    "#prompt = \"This image is provided for inference of neural networl classification for alzheimer's disease. Tell me if there is any sign of alzheimer's disease in this image.\" \n",
    "#try:\n",
    "    #result = predict_image(img_file, prompt)\n",
    "    #print(\"Inference result:\", result)\n",
    "#except Exception as e:\n",
    "    #print(\"Error during inference:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medgemma_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
